{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two tasks that I need to complete for this week.\n",
    "\n",
    "Firstly is building my own learning class/object/thingy.\n",
    "\n",
    "Secondly I need to use this new learner object to create a model to classify the MNIST dataset.\n",
    "\n",
    "Exciting!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed modules\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from fastai.vision.all import *\n",
    "\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# built int\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building learner\n",
    "\n",
    "A learner needs 4 bits of information to work\n",
    "- Data\n",
    "- Model\n",
    "- Optimizer\n",
    "- Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOptimizer:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        for p in self.params:\n",
    "            with torch.no_grad():\n",
    "                p -= self.lr * p.grad\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.zero_()\n",
    "\n",
    "class MyLearner:\n",
    "    def __init__(self, dls, model, loss_func, metric_func):\n",
    "        self.dls = dls\n",
    "        self.model = model\n",
    "        self.loss_func = loss_func\n",
    "        self.metric_func = metric_func\n",
    "\n",
    "    def train_epoch(self, opt):\n",
    "        updates = 0\n",
    "        for xb, yb in self.dls.train:\n",
    "            updates += 1\n",
    "            pred = self.model(xb)\n",
    "            loss = self.loss_func(pred, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        print(f\"Train loops: {updates}\")\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def validate_epoch(self):\n",
    "        with torch.no_grad():\n",
    "            accs = [self.metric_func(self.model(xb), yb) for xb,yb in self.dls.valid]\n",
    "        return round(torch.stack(accs).mean().item(), 4) \n",
    "\n",
    "    \n",
    "    def fit(self, epochs, lr):\n",
    "        opt = MyOptimizer(self.model.parameters(), lr)\n",
    "        opt.zero_grad()\n",
    "        print(\"Epoch Train_Loss Valid_Accuracy  Time\")\n",
    "        for epoch in range(epochs):\n",
    "            start = time.time()\n",
    "            train_loss = self.train_epoch(opt)\n",
    "            end = time.time()\n",
    "            accuracy = self.validate_epoch()\n",
    "            print(f\" {epoch:02}:    {train_loss:.4f}     {accuracy:.4f}   {end-start:.4f}\")\n",
    "\n",
    "        \n",
    "    def transform(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Takes a tensor of shape (1,784) return a list of ints\n",
    "        preds = self.transform(x).argmax(dim=0)\n",
    "        return preds.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 and 7 MNIST calssifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "\n",
    "stacked_3d = torch.stack(three_tensors).float()/255\n",
    "stacked_7d = torch.stack(seven_tensors).float()/255\n",
    "\n",
    "train_x = torch.cat([stacked_3d, stacked_7d]).view(-1, 28*28)\n",
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n",
    "\n",
    "dset = list(zip(train_x, train_y))\n",
    "x,y = dset[0]\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), torch.Size([1]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(dset)\n",
    "\n",
    "xb,yb = first(dl)\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([1]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x = torch.cat([\n",
    "    torch.stack([\n",
    "        tensor(Image.open(o)).float()/255\n",
    "        for o in (path/'valid'/'3').ls()\n",
    "    ]),\n",
    "    torch.stack([\n",
    "        tensor(Image.open(o)).float()/255\n",
    "        for o in (path/'valid'/'7').ls()\n",
    "    ])\n",
    "]).view(-1, 28*28)\n",
    "\n",
    "valid_y = tensor([1]*len((path/'valid'/'3').ls()) + [0]*len((path/'valid'/'7').ls())).unsqueeze(1)\n",
    "\n",
    "valid_dset = list(zip(valid_x, valid_y))\n",
    "x,y = valid_dset[0]\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), torch.Size([1]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dl = DataLoader(valid_dset)\n",
    "\n",
    "xb,yb = first(valid_dl)\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4460)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mnist_loss(preds, targets):\n",
    "    preds = preds.sigmoid()\n",
    "    return torch.where(targets==1, 1-preds, preds).mean()\n",
    "\n",
    "mnist_loss(torch.tensor([0.9, 0.4, 0.2]), tensor([1,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6667)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mnist_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()\n",
    "\n",
    "mnist_accuracy(torch.tensor([0.9, 0.4, 0.2]), tensor([1,0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all togather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.train.one_batch()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train_Loss Valid_Accuracy  Time\n",
      "Train loops: 12396\n",
      " 00:    0.0023     0.5118   3.5886\n",
      "Train loops: 12396\n",
      " 01:    0.0007     0.8292   3.7498\n",
      "Train loops: 12396\n",
      " 02:    0.0004     0.9190   4.5181\n",
      "Train loops: 12396\n",
      " 03:    0.0003     0.9426   4.7744\n",
      "Train loops: 12396\n",
      " 04:    0.0002     0.9563   3.5970\n",
      "Train loops: 12396\n",
      " 05:    0.0002     0.9661   3.4616\n",
      "Train loops: 12396\n",
      " 06:    0.0002     0.9676   3.7780\n",
      "Train loops: 12396\n",
      " 07:    0.0001     0.9676   3.9274\n",
      "Train loops: 12396\n",
      " 08:    0.0001     0.9701   3.5247\n",
      "Train loops: 12396\n",
      " 09:    0.0001     0.9711   3.9182\n",
      "Train loops: 12396\n",
      " 10:    0.0001     0.9725   3.5024\n",
      "Train loops: 12396\n",
      " 11:    0.0001     0.9730   3.6048\n",
      "Train loops: 12396\n",
      " 12:    0.0001     0.9745   3.4185\n",
      "Train loops: 12396\n",
      " 13:    0.0001     0.9750   3.3832\n",
      "Train loops: 12396\n",
      " 14:    0.0001     0.9755   3.4099\n",
      "Train loops: 12396\n",
      " 15:    0.0001     0.9755   3.3242\n",
      "Train loops: 12396\n",
      " 16:    0.0001     0.9769   3.3767\n",
      "Train loops: 12396\n",
      " 17:    0.0001     0.9769   3.4246\n",
      "Train loops: 12396\n",
      " 18:    0.0001     0.9769   3.3773\n",
      "Train loops: 12396\n",
      " 19:    0.0001     0.9769   3.3494\n"
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(28*28, 1)\n",
    "\n",
    "learner = MyLearner(dls, linear_model, mnist_loss, mnist_accuracy)\n",
    "\n",
    "learner.fit(20, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train_Loss Valid_Accuracy  Time\n",
      "Train loops: 12396\n",
      " 00:    0.0037     0.5044   5.4948\n",
      "Train loops: 12396\n",
      " 01:    0.0006     0.7512   5.5774\n",
      "Train loops: 12396\n",
      " 02:    0.0002     0.8813   5.5449\n",
      "Train loops: 12396\n",
      " 03:    0.0001     0.9181   5.4589\n",
      "Train loops: 12396\n",
      " 04:    0.0001     0.9362   5.5031\n",
      "Train loops: 12396\n",
      " 05:    0.0000     0.9500   5.4912\n",
      "Train loops: 12396\n",
      " 06:    0.0000     0.9578   5.4871\n",
      "Train loops: 12396\n",
      " 07:    0.0000     0.9607   5.5752\n",
      "Train loops: 12396\n",
      " 08:    0.0000     0.9652   5.6467\n",
      "Train loops: 12396\n",
      " 09:    0.0000     0.9681   5.5447\n",
      "Train loops: 12396\n",
      " 10:    0.0000     0.9691   5.4525\n",
      "Train loops: 12396\n",
      " 11:    0.0000     0.9706   5.2736\n",
      "Train loops: 12396\n",
      " 12:    0.0000     0.9735   5.1758\n",
      "Train loops: 12396\n",
      " 13:    0.0000     0.9745   5.3209\n",
      "Train loops: 12396\n",
      " 14:    0.0000     0.9750   5.5401\n",
      "Train loops: 12396\n",
      " 15:    0.0000     0.9755   5.3954\n",
      "Train loops: 12396\n",
      " 16:    0.0000     0.9760   5.3875\n",
      "Train loops: 12396\n",
      " 17:    0.0000     0.9764   5.5870\n",
      "Train loops: 12396\n",
      " 18:    0.0000     0.9764   5.3483\n",
      "Train loops: 12396\n",
      " 19:    0.0000     0.9769   5.3266\n"
     ]
    }
   ],
   "source": [
    "nn_basic = nn.Sequential(\n",
    "    nn.Linear(28*28, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 1),\n",
    ")\n",
    "\n",
    "learner = MyLearner(dls, nn_basic, mnist_loss, mnist_accuracy)\n",
    "\n",
    "learner.fit(20, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/james/.fastai/data/mnist_png/testing'),Path('/home/james/.fastai/data/mnist_png/training')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 12000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = (path/'training').ls().sorted()\n",
    "\n",
    "all_data = [(tensor(Image.open(o)), int(path.name))\n",
    "            for path in train_path\n",
    "            for o in (path).ls()]\n",
    "\n",
    "all_data\n",
    "\n",
    "# shuffle\n",
    "\n",
    "random.shuffle(all_data)\n",
    "\n",
    "\n",
    "split = int(len(all_data)*0.8)\n",
    "\n",
    "train_data = all_data[:split]\n",
    "valid_data = all_data[split:]\n",
    "\n",
    "len(train_data), len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48000, 784]) torch.Size([48000, 1])\n",
      "48000\n",
      "torch.Size([12000, 784]) torch.Size([12000, 1])\n",
      "12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 784]), torch.Size([64, 1]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dl(data_list):\n",
    "    x = torch.stack([o[0] for o in data_list]).float()/255\n",
    "    x = x.view(-1, 28*28)\n",
    "    y = tensor([o[1] for o in data_list]).unsqueeze(1)\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "    dset = list(zip(x,y))\n",
    "\n",
    "    print(len(dset))\n",
    "\n",
    "    dl = DataLoader(dset, batch_size=64)\n",
    "\n",
    "    return dl\n",
    "\n",
    "train_dl = get_dl(train_data)\n",
    "valid_dl = get_dl(valid_data)\n",
    "\n",
    "train_dl.one_batch()[0].shape, valid_dl.one_batch()[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_samples(batch, num_samples=10):\n",
    "    # Get a batch of data from the data loader\n",
    "    images, labels = batch\n",
    "    images = images.view(-1, 28, 28)  # Reshape images to 28x28\n",
    "    \n",
    "    # Plot the specified number of samples\n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 3))\n",
    "    for i in range(num_samples):\n",
    "        axes[i].imshow(images[i].numpy(), cmap='gray')\n",
    "        axes[i].set_title(f'Label: {labels[i].item()}')\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize samples from training and validation data loaders\n",
    "visualize_samples(train_dl.one_batch())\n",
    "visualize_samples(valid_dl.one_batch())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Needed function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_model = nn.Sequential(\n",
    "    nn.Linear(28*28, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 10)\n",
    ")\n",
    "\n",
    "# mnist_model = nn.Sequential(\n",
    "#     nn.Linear(28*28, 128),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(128, 64),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(64, 10)\n",
    "# )\n",
    "\n",
    "mnist_model(train_dl.one_batch()[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 10]), torch.Size([64, 1]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = mnist_model(train_dl.one_batch()[0])\n",
    "targets = train_dl.one_batch()[1]\n",
    "\n",
    "preds.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 3, 5, 1, 1, 2, 6, 8, 0, 4, 2, 7, 7, 2, 1, 1, 9, 0, 4, 8, 8, 7, 0,\n",
       "        3, 6, 0, 1, 7, 3, 5, 0, 6, 8, 9, 1, 9, 9, 7, 9, 1, 2, 8, 8, 8, 6, 3, 9,\n",
       "        5, 4, 9, 2, 6, 3, 1, 8, 4, 2, 5, 5, 5, 3, 6, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9261, 0.7523, 0.7815, 0.5587, 0.9547, 0.3564, 0.9957, 0.5457, 0.9605,\n",
       "         0.7544],\n",
       "        [0.7494, 0.8851, 0.9722, 0.9944, 0.3382, 0.7579, 0.5753, 0.2673, 0.1166,\n",
       "         0.3712],\n",
       "        [0.0948, 0.6444, 0.0074, 0.1551, 0.0752, 0.8233, 0.2820, 0.0842, 0.5581,\n",
       "         0.2289],\n",
       "        [0.2603, 0.6603, 0.6184, 0.3055, 0.7156, 0.6018, 0.3889, 0.0617, 0.7188,\n",
       "         0.6093],\n",
       "        [0.6258, 0.9553, 0.1366, 0.4280, 0.8662, 0.4507, 0.7663, 0.3752, 0.7364,\n",
       "         0.8468]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([9, 5, 7, 4, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.2334)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def complete_mnist_loss(preds, targets):\n",
    "    # preds = preds.softmax(1)\n",
    "    # display(preds)\n",
    "    # targets = targets.view(-1)\n",
    "    # targets_probs = preds[range(targets.shape[0]), targets]\n",
    "\n",
    "    # display(targets_probs)\n",
    "    # return -torch.log(targets_probs).mean()\n",
    "\n",
    "    # print(preds.shape, targets.shape)\n",
    "    # print(targets * preds.log())\n",
    "    # return -(targets * preds.log()).sum() / len(preds)\n",
    "    return nn.functional.cross_entropy(preds, targets.squeeze())\n",
    "    \n",
    "random_preds = tensor([[0.9261, 0.7523, 0.7815, 0.5587, 0.9547, 0.3564, 0.9957, 0.5457, 0.9605,\n",
    "         0.7544],\n",
    "        [0.7494, 0.8851, 0.9722, 0.9944, 0.3382, 0.7579, 0.5753, 0.2673, 0.1166,\n",
    "         0.3712],\n",
    "        [0.0948, 0.6444, 0.0074, 0.1551, 0.0752, 0.8233, 0.2820, 0.0842, 0.5581,\n",
    "         0.2289],\n",
    "        [0.2603, 0.6603, 0.6184, 0.3055, 0.7156, 0.6018, 0.3889, 0.0617, 0.7188,\n",
    "         0.6093],\n",
    "        [0.6258, 0.9553, 0.1366, 0.4280, 0.8662, 0.4507, 0.7663, 0.3752, 0.7364,\n",
    "         0.8468]])\n",
    "display(random_preds)\n",
    "random_targets = tensor([9, 5, 7, 4, 1])\n",
    "display(random_targets)\n",
    "complete_mnist_loss(random_preds, random_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2472, 0.8071, 0.6438, 0.7001, 0.5046, 0.4333, 0.2999, 0.5597, 0.7503,\n",
       "         0.1459],\n",
       "        [0.8508, 0.1171, 0.0273, 0.2872, 0.3250, 0.4297, 0.2196, 0.7902, 0.1327,\n",
       "         0.8547],\n",
       "        [0.6367, 0.8120, 0.8256, 0.7937, 0.3605, 0.4780, 0.1094, 0.8865, 0.8531,\n",
       "         0.1587],\n",
       "        [0.8184, 0.6203, 0.0273, 0.8205, 0.5324, 0.4460, 0.1424, 0.0323, 0.9509,\n",
       "         0.7708],\n",
       "        [0.0875, 0.9155, 0.5544, 0.0337, 0.9919, 0.0979, 0.7772, 0.7446, 0.5790,\n",
       "         0.3651]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[4],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [7]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def complete_mnist_accuracy(preds, targets):\n",
    "    preds = preds.argmax(dim=1)\n",
    "    targets = targets.squeeze()\n",
    "    correct = (preds == targets).float()\n",
    "    return correct.float().mean()\n",
    "\n",
    "random_preds = torch.rand((5, 10))\n",
    "display(random_preds)\n",
    "random_targets = torch.randint(0, 10, (5, 1))\n",
    "display(random_targets)\n",
    "complete_mnist_accuracy(random_preds, random_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train_Loss Valid_Accuracy  Time\n",
      "Train loops: 750\n",
      " 00:    0.2236     0.9364   0.9260\n",
      "Train loops: 750\n",
      " 01:    0.2204     0.9377   0.7898\n",
      "Train loops: 750\n",
      " 02:    0.2169     0.9386   0.9310\n",
      "Train loops: 750\n",
      " 03:    0.2137     0.9399   0.6557\n",
      "Train loops: 750\n",
      " 04:    0.2108     0.9405   0.5789\n",
      "Train loops: 750\n",
      " 05:    0.2075     0.9408   0.5567\n",
      "Train loops: 750\n",
      " 06:    0.2043     0.9415   0.5665\n",
      "Train loops: 750\n",
      " 07:    0.2016     0.9423   0.5567\n",
      "Train loops: 750\n",
      " 08:    0.1983     0.9427   0.5778\n",
      "Train loops: 750\n",
      " 09:    0.1954     0.9432   0.6502\n",
      "Train loops: 750\n",
      " 10:    0.1927     0.9439   0.5802\n",
      "Train loops: 750\n",
      " 11:    0.1896     0.9446   0.5839\n",
      "Train loops: 750\n",
      " 12:    0.1865     0.9451   0.5784\n",
      "Train loops: 750\n",
      " 13:    0.1837     0.9457   0.7784\n",
      "Train loops: 750\n",
      " 14:    0.1806     0.9466   0.6121\n",
      "Train loops: 750\n",
      " 15:    0.1779     0.9470   0.6739\n",
      "Train loops: 750\n",
      " 16:    0.1748     0.9473   0.6932\n",
      "Train loops: 750\n",
      " 17:    0.1719     0.9481   0.6989\n",
      "Train loops: 750\n",
      " 18:    0.1687     0.9484   0.6472\n",
      "Train loops: 750\n",
      " 19:    0.1659     0.9491   0.6354\n"
     ]
    }
   ],
   "source": [
    "\n",
    "learner = MyLearner(dls, mnist_model, complete_mnist_loss, complete_mnist_accuracy)\n",
    "\n",
    "learner.fit(20, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.predict(train_dl.one_batch()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 8, 9, 6, 3, 1, 3, 5, 9, 5, 1, 4, 3, 3, 6, 6, 6, 8, 9, 1, 7, 1, 5, 8,\n",
       "        0, 5, 3, 5, 9, 9, 8, 2, 9, 8, 7, 0, 8, 0, 4, 4, 2, 1, 1, 7, 6, 2, 6, 8,\n",
       "        5, 6, 2, 9, 6, 9, 7, 8, 0, 4, 1, 0, 7, 7, 6, 0], device='cuda:0')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl.one_batch()[1].squeeze(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 3, 9, 0, 3, 1, 3, 3, 9, 3, 1, 0, 3, 3, 3, 0, 6, 3, 9, 1, 7, 1, 3, 3,\n",
       "        0, 3, 3, 2, 9, 9, 3, 0, 3, 3, 7, 0, 3, 3, 9, 0, 2, 1, 3, 7, 6, 2, 6, 3,\n",
       "        3, 3, 3, 9, 3, 9, 3, 7, 0, 9, 3, 0, 7, 7, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_model(train_dl.one_batch()[0]).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradio app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7885\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7885/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.50.2, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "tensor([[0.6745, 0.6706, 0.6667, 0.6667, 0.6706, 0.6667, 0.6667, 0.6627, 0.6588,\n",
      "         0.6588, 0.6627, 0.6627, 0.6627, 0.6588, 0.6510, 0.6549, 0.6588, 0.6588,\n",
      "         0.6549, 0.6549, 0.6549, 0.6510, 0.6510, 0.6510, 0.6510, 0.6549, 0.6549,\n",
      "         0.6510, 0.6784, 0.6706, 0.6627, 0.6667, 0.6667, 0.6667, 0.6706, 0.6667,\n",
      "         0.6627, 0.6588, 0.6588, 0.6627, 0.6588, 0.5843, 0.5294, 0.6431, 0.6549,\n",
      "         0.6549, 0.6510, 0.6549, 0.6549, 0.6471, 0.6510, 0.6510, 0.6549, 0.6549,\n",
      "         0.6549, 0.6471, 0.6745, 0.6706, 0.6667, 0.6667, 0.6667, 0.6667, 0.6706,\n",
      "         0.6706, 0.6627, 0.6588, 0.6588, 0.6588, 0.6157, 0.4392, 0.5647, 0.6471,\n",
      "         0.6549, 0.6549, 0.6549, 0.6549, 0.6510, 0.6471, 0.6471, 0.6471, 0.6510,\n",
      "         0.6549, 0.6549, 0.6510, 0.6784, 0.6745, 0.6667, 0.6667, 0.6667, 0.6667,\n",
      "         0.6706, 0.6706, 0.6667, 0.6588, 0.6627, 0.6549, 0.4627, 0.5176, 0.6510,\n",
      "         0.6549, 0.6549, 0.6510, 0.6549, 0.6549, 0.6549, 0.6549, 0.6510, 0.6510,\n",
      "         0.6471, 0.6510, 0.6549, 0.6510, 0.6784, 0.6745, 0.6706, 0.6667, 0.6667,\n",
      "         0.6667, 0.6667, 0.6706, 0.6667, 0.6667, 0.6667, 0.6039, 0.3922, 0.6196,\n",
      "         0.6549, 0.6549, 0.6510, 0.6510, 0.6549, 0.6510, 0.6510, 0.6549, 0.6510,\n",
      "         0.6510, 0.6510, 0.6510, 0.6510, 0.6510, 0.6784, 0.6706, 0.6706, 0.6667,\n",
      "         0.6706, 0.6667, 0.6667, 0.6706, 0.6706, 0.6667, 0.6667, 0.4941, 0.4902,\n",
      "         0.6510, 0.6549, 0.6549, 0.6471, 0.6510, 0.6549, 0.6588, 0.6549, 0.6549,\n",
      "         0.6510, 0.6549, 0.6510, 0.6549, 0.6510, 0.6471, 0.6784, 0.6745, 0.6706,\n",
      "         0.6667, 0.6706, 0.6667, 0.6706, 0.6706, 0.6706, 0.6667, 0.6314, 0.4000,\n",
      "         0.6000, 0.6510, 0.6549, 0.6588, 0.6510, 0.6510, 0.6549, 0.6549, 0.6588,\n",
      "         0.6549, 0.6549, 0.6510, 0.6549, 0.6510, 0.6549, 0.6510, 0.6745, 0.6706,\n",
      "         0.6706, 0.6667, 0.6706, 0.6706, 0.6667, 0.6706, 0.6706, 0.6667, 0.5608,\n",
      "         0.4235, 0.6392, 0.6510, 0.6549, 0.6549, 0.6549, 0.6510, 0.6549, 0.6549,\n",
      "         0.6588, 0.6588, 0.6549, 0.6549, 0.6471, 0.6510, 0.6549, 0.6510, 0.6706,\n",
      "         0.6706, 0.6706, 0.6706, 0.6667, 0.6667, 0.6667, 0.6667, 0.6706, 0.6627,\n",
      "         0.4627, 0.5059, 0.6471, 0.6510, 0.6549, 0.6510, 0.6510, 0.6510, 0.6549,\n",
      "         0.6549, 0.6549, 0.6549, 0.6549, 0.6549, 0.6471, 0.6510, 0.6549, 0.6510,\n",
      "         0.6745, 0.6706, 0.6667, 0.6706, 0.6667, 0.6667, 0.6667, 0.6667, 0.6706,\n",
      "         0.6353, 0.3725, 0.5922, 0.6510, 0.6471, 0.6510, 0.6510, 0.6510, 0.6510,\n",
      "         0.6549, 0.6549, 0.6549, 0.6510, 0.6549, 0.6549, 0.6549, 0.6510, 0.6549,\n",
      "         0.6549, 0.6745, 0.6667, 0.6706, 0.6706, 0.6667, 0.6706, 0.6706, 0.6706,\n",
      "         0.6706, 0.5686, 0.4000, 0.6353, 0.6471, 0.6510, 0.6510, 0.6510, 0.6510,\n",
      "         0.6471, 0.6510, 0.6471, 0.6510, 0.6510, 0.6510, 0.6549, 0.6588, 0.6549,\n",
      "         0.6510, 0.6471, 0.6706, 0.6627, 0.6667, 0.6706, 0.6667, 0.6706, 0.6706,\n",
      "         0.6706, 0.6706, 0.5098, 0.4667, 0.6510, 0.6510, 0.6471, 0.6510, 0.6510,\n",
      "         0.6471, 0.6471, 0.6471, 0.6471, 0.6471, 0.6510, 0.6510, 0.6549, 0.6549,\n",
      "         0.6549, 0.6510, 0.6471, 0.6627, 0.6667, 0.6667, 0.6667, 0.6667, 0.6706,\n",
      "         0.6706, 0.6667, 0.6667, 0.4784, 0.5098, 0.6510, 0.6549, 0.6510, 0.6471,\n",
      "         0.6471, 0.6471, 0.6471, 0.6471, 0.6431, 0.6431, 0.6431, 0.6510, 0.6510,\n",
      "         0.6549, 0.6588, 0.6510, 0.6471, 0.6588, 0.6667, 0.6667, 0.6667, 0.6667,\n",
      "         0.6667, 0.6667, 0.6667, 0.6627, 0.4353, 0.5451, 0.6549, 0.6549, 0.6549,\n",
      "         0.6471, 0.6471, 0.6471, 0.6471, 0.6471, 0.6431, 0.6431, 0.6431, 0.6471,\n",
      "         0.6471, 0.6510, 0.6549, 0.6510, 0.6510, 0.6627, 0.6627, 0.6667, 0.6706,\n",
      "         0.6706, 0.6627, 0.6667, 0.6706, 0.6627, 0.4392, 0.5490, 0.6549, 0.6588,\n",
      "         0.6510, 0.6510, 0.6471, 0.6471, 0.6471, 0.6431, 0.6431, 0.6471, 0.6471,\n",
      "         0.6471, 0.6510, 0.6471, 0.6510, 0.6510, 0.6510, 0.6588, 0.6627, 0.6667,\n",
      "         0.6706, 0.6706, 0.6667, 0.6667, 0.6706, 0.6627, 0.4235, 0.5647, 0.6549,\n",
      "         0.6549, 0.6431, 0.6039, 0.6157, 0.6431, 0.6431, 0.6431, 0.6431, 0.6431,\n",
      "         0.6431, 0.6431, 0.6471, 0.6471, 0.6510, 0.6510, 0.6510, 0.6627, 0.6588,\n",
      "         0.6627, 0.6667, 0.6706, 0.6706, 0.6667, 0.6706, 0.6549, 0.4039, 0.5882,\n",
      "         0.6510, 0.5843, 0.4824, 0.4431, 0.3961, 0.5569, 0.6353, 0.6431, 0.6471,\n",
      "         0.6431, 0.6431, 0.6431, 0.6471, 0.6510, 0.6549, 0.6510, 0.6510, 0.6627,\n",
      "         0.6588, 0.6627, 0.6627, 0.6627, 0.6667, 0.6667, 0.6706, 0.6549, 0.4078,\n",
      "         0.5843, 0.5569, 0.4314, 0.5647, 0.6314, 0.5961, 0.5647, 0.5608, 0.6353,\n",
      "         0.6431, 0.6471, 0.6471, 0.6431, 0.6471, 0.6471, 0.6510, 0.6510, 0.6471,\n",
      "         0.6588, 0.6588, 0.6627, 0.6588, 0.6627, 0.6667, 0.6667, 0.6706, 0.6627,\n",
      "         0.4314, 0.5451, 0.4118, 0.5804, 0.6549, 0.6510, 0.6549, 0.6431, 0.4863,\n",
      "         0.5843, 0.6431, 0.6431, 0.6431, 0.6431, 0.6471, 0.6471, 0.6510, 0.6549,\n",
      "         0.6471, 0.6588, 0.6627, 0.6627, 0.6627, 0.6667, 0.6627, 0.6667, 0.6706,\n",
      "         0.6667, 0.4510, 0.5529, 0.6078, 0.6549, 0.6549, 0.6510, 0.6510, 0.6510,\n",
      "         0.4824, 0.5216, 0.6431, 0.6431, 0.6471, 0.6431, 0.6431, 0.6471, 0.6510,\n",
      "         0.6510, 0.6471, 0.6549, 0.6627, 0.6627, 0.6627, 0.6667, 0.6667, 0.6667,\n",
      "         0.6706, 0.6627, 0.4549, 0.5294, 0.6510, 0.6549, 0.6510, 0.6549, 0.6510,\n",
      "         0.6471, 0.5216, 0.4784, 0.6431, 0.6431, 0.6431, 0.6431, 0.6431, 0.6431,\n",
      "         0.6510, 0.6510, 0.6510, 0.6588, 0.6627, 0.6627, 0.6627, 0.6627, 0.6667,\n",
      "         0.6667, 0.6667, 0.6706, 0.4980, 0.4706, 0.6510, 0.6510, 0.6510, 0.6510,\n",
      "         0.6471, 0.6510, 0.5176, 0.5020, 0.6392, 0.6431, 0.6471, 0.6431, 0.6392,\n",
      "         0.6392, 0.6471, 0.6510, 0.6510, 0.6588, 0.6588, 0.6588, 0.6627, 0.6627,\n",
      "         0.6667, 0.6667, 0.6667, 0.6706, 0.5765, 0.3922, 0.6392, 0.6510, 0.6510,\n",
      "         0.6510, 0.6471, 0.6471, 0.4627, 0.5529, 0.6431, 0.6431, 0.6431, 0.6471,\n",
      "         0.6471, 0.6431, 0.6471, 0.6471, 0.6471, 0.6588, 0.6588, 0.6627, 0.6627,\n",
      "         0.6627, 0.6627, 0.6667, 0.6667, 0.6706, 0.6431, 0.3804, 0.5294, 0.6471,\n",
      "         0.6510, 0.6510, 0.6471, 0.6078, 0.3922, 0.6000, 0.6431, 0.6431, 0.6471,\n",
      "         0.6431, 0.6471, 0.6510, 0.6471, 0.6471, 0.6471, 0.6627, 0.6588, 0.6627,\n",
      "         0.6588, 0.6588, 0.6627, 0.6667, 0.6667, 0.6667, 0.6627, 0.5608, 0.3608,\n",
      "         0.4980, 0.6157, 0.6353, 0.6235, 0.4745, 0.4510, 0.6353, 0.6392, 0.6431,\n",
      "         0.6471, 0.6471, 0.6471, 0.6471, 0.6471, 0.6471, 0.6471, 0.6588, 0.6588,\n",
      "         0.6588, 0.6627, 0.6627, 0.6627, 0.6667, 0.6627, 0.6627, 0.6667, 0.6627,\n",
      "         0.5725, 0.3843, 0.3686, 0.3804, 0.4039, 0.4980, 0.6235, 0.6431, 0.6392,\n",
      "         0.6431, 0.6471, 0.6471, 0.6471, 0.6471, 0.6510, 0.6471, 0.6471, 0.6588,\n",
      "         0.6627, 0.6588, 0.6588, 0.6588, 0.6588, 0.6627, 0.6627, 0.6627, 0.6667,\n",
      "         0.6667, 0.6627, 0.6471, 0.6039, 0.5686, 0.6078, 0.6431, 0.6471, 0.6431,\n",
      "         0.6431, 0.6431, 0.6471, 0.6471, 0.6471, 0.6431, 0.6471, 0.6471, 0.6431,\n",
      "         0.6588, 0.6627, 0.6588, 0.6588, 0.6588, 0.6549, 0.6588, 0.6588, 0.6627,\n",
      "         0.6627, 0.6627, 0.6627, 0.6588, 0.6510, 0.6549, 0.6549, 0.6510, 0.6510,\n",
      "         0.6431, 0.6431, 0.6431, 0.6431, 0.6471, 0.6471, 0.6471, 0.6431, 0.6392,\n",
      "         0.6471]])\n",
      "tensor([[0.9647, 0.9608, 0.9608, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9608, 0.9608, 0.9608, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9608, 0.9451, 0.7843, 0.6706, 0.7765, 0.9137, 0.9608, 0.9608, 0.9608,\n",
      "         0.9608, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9647, 0.9608, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9647, 0.9529, 0.6549, 0.1255, 0.0353, 0.0941, 0.2863, 0.7569, 0.9569,\n",
      "         0.9647, 0.9608, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9608, 0.8941, 0.5725, 0.1176, 0.0000, 0.0000, 0.0000, 0.0000, 0.1725,\n",
      "         0.8118, 0.9647, 0.9647, 0.9608, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9216, 0.6706, 0.2627, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1725, 0.8471, 0.9647, 0.9647, 0.9647, 0.9647, 0.9608, 0.9647, 0.9647,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9608, 0.9647, 0.9647, 0.9647, 0.9373,\n",
      "         0.7294, 0.3294, 0.0549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0275, 0.5843, 0.9569, 0.9647, 0.9608, 0.9608, 0.9647, 0.9608, 0.9647,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9608, 0.9647, 0.9490, 0.7804,\n",
      "         0.3922, 0.0784, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.2000, 0.8706, 0.9608, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9529, 0.8196, 0.4549,\n",
      "         0.1137, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0235, 0.5882, 0.9608, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9608, 0.8510, 0.5059, 0.1451,\n",
      "         0.0078, 0.0000, 0.0000, 0.0000, 0.0118, 0.1608, 0.2431, 0.0078, 0.0000,\n",
      "         0.0000, 0.0000, 0.1608, 0.8549, 0.9647, 0.9647, 0.9647, 0.9647, 0.9608,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9569, 0.4471, 0.0157,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0824, 0.4314, 0.8039, 0.3569, 0.0000,\n",
      "         0.0000, 0.0000, 0.0078, 0.4784, 0.9569, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9647, 0.9647, 0.9608, 0.9647, 0.9647, 0.9647, 0.9647, 0.9608, 0.6902,\n",
      "         0.1804, 0.0235, 0.0039, 0.0314, 0.2235, 0.6980, 0.9412, 0.7373, 0.0784,\n",
      "         0.0000, 0.0000, 0.0000, 0.0863, 0.7725, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9608, 0.9608, 0.9608, 0.9608, 0.9647, 0.9608, 0.9608, 0.9647, 0.9647,\n",
      "         0.9569, 0.8588, 0.6471, 0.5725, 0.6863, 0.8706, 0.9608, 0.9333, 0.3725,\n",
      "         0.0039, 0.0000, 0.0000, 0.0000, 0.3373, 0.9294, 0.9647, 0.9647, 0.9608,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9647, 0.9647, 0.9608, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.7490,\n",
      "         0.0863, 0.0000, 0.0000, 0.0000, 0.0863, 0.7137, 0.9608, 0.9647, 0.9647,\n",
      "         0.9608, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9333,\n",
      "         0.3647, 0.0039, 0.0000, 0.0000, 0.0039, 0.4549, 0.9451, 0.9647, 0.9647,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9608, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.7412, 0.0745, 0.0000, 0.0000, 0.0000, 0.0824, 0.7490, 0.9647, 0.9647,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9608, 0.9647,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9608, 0.9647, 0.9647, 0.9647,\n",
      "         0.9412, 0.3961, 0.0039, 0.0000, 0.0000, 0.0039, 0.4000, 0.9373, 0.9647,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9608, 0.9647, 0.9647, 0.9608,\n",
      "         0.9608, 0.9647, 0.9647, 0.9647, 0.9608, 0.9647, 0.9608, 0.9608, 0.9608,\n",
      "         0.9608, 0.7451, 0.0824, 0.0000, 0.0000, 0.0000, 0.0863, 0.7529, 0.9647,\n",
      "         0.9647, 0.9608, 0.9608, 0.9647, 0.9608, 0.9608, 0.9608, 0.9608, 0.9647,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9608, 0.9608, 0.9647,\n",
      "         0.9647, 0.9294, 0.3765, 0.0039, 0.0000, 0.0000, 0.0000, 0.3529, 0.9333,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9647, 0.9647, 0.7294, 0.0745, 0.0000, 0.0000, 0.0000, 0.0745, 0.7176,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9608, 0.9647, 0.9255, 0.3294, 0.0039, 0.0000, 0.0000, 0.0000, 0.2745,\n",
      "         0.9216, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9647, 0.9608, 0.9647, 0.7961, 0.0980, 0.0000, 0.0000, 0.0000, 0.0196,\n",
      "         0.5490, 0.9569, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9608, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9647, 0.9647, 0.9608, 0.9333, 0.4275, 0.0118, 0.0000, 0.0000, 0.0000,\n",
      "         0.1647, 0.8471, 0.9608, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9608, 0.9647, 0.9608, 0.9608, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9647, 0.9647, 0.9647, 0.9608, 0.6588, 0.0706, 0.0000, 0.0000, 0.0000,\n",
      "         0.0078, 0.4824, 0.9529, 0.9608, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9647, 0.9608, 0.9647, 0.9647, 0.9647, 0.9608, 0.9569, 0.9608, 0.9647,\n",
      "         0.9647, 0.9647, 0.9647, 0.9647, 0.9216, 0.2745, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0510, 0.6745, 0.8941, 0.8863, 0.8706, 0.8235, 0.6902, 0.5294,\n",
      "         0.6235, 0.7529, 0.8902, 0.9608, 0.9608, 0.9412, 0.6824, 0.3922, 0.4627,\n",
      "         0.5882, 0.6627, 0.6549, 0.5843, 0.5176, 0.4824, 0.1255, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0118, 0.1333, 0.1882, 0.1804, 0.1529, 0.1059, 0.0431,\n",
      "         0.0039, 0.0157, 0.0627, 0.2275, 0.6588, 0.9490, 0.7176, 0.0980, 0.0000,\n",
      "         0.0000, 0.0078, 0.0235, 0.0196, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1216, 0.7765, 0.7020, 0.0745,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0039, 0.0078, 0.0235, 0.0353, 0.0471, 0.0510, 0.0706, 0.0745,\n",
      "         0.1098, 0.1373, 0.1529, 0.1176, 0.0784, 0.0784, 0.1608, 0.7412, 0.9294,\n",
      "         0.6588, 0.3451, 0.1804, 0.1490, 0.2039, 0.2549, 0.3098, 0.3490, 0.3843,\n",
      "         0.4314, 0.4667, 0.5373, 0.5961, 0.6588, 0.7098, 0.7294, 0.7451, 0.7804,\n",
      "         0.7843, 0.8314, 0.8549, 0.8706, 0.8353, 0.7922, 0.7882, 0.8431, 0.9490,\n",
      "         0.9647, 0.9608, 0.9373, 0.8784, 0.8549, 0.8941, 0.9216, 0.9412, 0.9490,\n",
      "         0.9569, 0.9608, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9608, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647, 0.9647,\n",
      "         0.9608]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def classify_image(img):\n",
    "    # Convert the image to a PIL image if it's not already\n",
    "    if not isinstance(img, Image.Image):\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "    # Define the transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),  # Ensure the image is grayscale\n",
    "        transforms.Resize((28, 28)),  # Resize to 28x28\n",
    "        transforms.ToTensor(),  # Convert to tensor\n",
    "        transforms.Normalize((0.5,), (0.5,))  # Normalize the image\n",
    "    ])\n",
    "    \n",
    "    # Apply the transformations\n",
    "    img_tensor = transform(img)  \n",
    "\n",
    "    # De-normalize the image for proper visualization\n",
    "    img_tensor = img_tensor * 0.5 + 0.5\n",
    "\n",
    "    # Convert the tensor to a numpy array and then to a PIL image\n",
    "    np_img = img_tensor.numpy().squeeze() * 255\n",
    "    transformed_img = Image.fromarray(np_img.astype(np.uint8))\n",
    "\n",
    "    # Flatten the tensor for prediction\n",
    "    img_tensor = img_tensor.view(-1, 28 * 28)\n",
    "    print(img_tensor)\n",
    "\n",
    "    prediction = learner.predict(img_tensor)[0]\n",
    "    \n",
    "    return prediction, transformed_img\n",
    "\n",
    "app = gr.Interface(fn=classify_image, inputs=\"image\", outputs=[\"label\", \"image\"])\n",
    "\n",
    "app.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
