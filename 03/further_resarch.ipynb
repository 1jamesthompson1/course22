{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two tasks that I need to complete for this week.\n",
    "\n",
    "Firstly is building my own learning class/object/thingy.\n",
    "\n",
    "Secondly I need to use this new learner object to create a model to classify the MNIST dataset.\n",
    "\n",
    "Exciting!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed modules\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from fastai.vision.all import *\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "# built int\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building learner\n",
    "\n",
    "A learner needs 4 bits of information to work\n",
    "- Data\n",
    "- Model\n",
    "- Optimizer\n",
    "- Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOptimizer:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        for p in self.params:\n",
    "            with torch.no_grad():\n",
    "                p -= self.lr * p.grad\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.zero_()\n",
    "\n",
    "class MyLearner:\n",
    "    def __init__(self, dls, model, loss_func, metric_func):\n",
    "        self.dls = dls\n",
    "        self.model = model\n",
    "        self.loss_func = loss_func\n",
    "        self.metric_func = metric_func\n",
    "\n",
    "    def train_epoch(self, opt):\n",
    "        updates = 0\n",
    "        for xb, yb in self.dls.train:\n",
    "            updates += 1\n",
    "            pred = self.model(xb)\n",
    "            loss = self.loss_func(pred, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        print(f\"Train loops: {updates}\")\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def validate_epoch(self):\n",
    "        with torch.no_grad():\n",
    "            accs = [self.metric_func(self.model(xb), yb) for xb,yb in self.dls.valid]\n",
    "        return round(torch.stack(accs).mean().item(), 4) \n",
    "\n",
    "    \n",
    "    def fit(self, epochs, lr):\n",
    "        opt = MyOptimizer(self.model.parameters(), lr)\n",
    "        opt.zero_grad()\n",
    "        print(\"Epoch Train_Loss Valid_Accuracy  Time\")\n",
    "        for epoch in range(epochs):\n",
    "            start = time.time()\n",
    "            train_loss = self.train_epoch(opt)\n",
    "            end = time.time()\n",
    "            accuracy = self.validate_epoch()\n",
    "            print(f\" {epoch:02}:    {train_loss:.4f}     {accuracy:.4f}   {end-start:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 and 7 MNIST calssifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([1]))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "\n",
    "stacked_3d = torch.stack(three_tensors).float()/255\n",
    "stacked_7d = torch.stack(seven_tensors).float()/255\n",
    "\n",
    "train_x = torch.cat([stacked_3d, stacked_7d]).view(-1, 28*28)\n",
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n",
    "\n",
    "dset = list(zip(train_x, train_y))\n",
    "x,y = dset[0]\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), torch.Size([1]))"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(dset)\n",
    "\n",
    "xb,yb = first(dl)\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([1]))"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x = torch.cat([\n",
    "    torch.stack([\n",
    "        tensor(Image.open(o)).float()/255\n",
    "        for o in (path/'valid'/'3').ls()\n",
    "    ]),\n",
    "    torch.stack([\n",
    "        tensor(Image.open(o)).float()/255\n",
    "        for o in (path/'valid'/'7').ls()\n",
    "    ])\n",
    "]).view(-1, 28*28)\n",
    "\n",
    "valid_y = tensor([1]*len((path/'valid'/'3').ls()) + [0]*len((path/'valid'/'7').ls())).unsqueeze(1)\n",
    "\n",
    "valid_dset = list(zip(valid_x, valid_y))\n",
    "x,y = valid_dset[0]\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), torch.Size([1]))"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dl = DataLoader(valid_dset)\n",
    "\n",
    "xb,yb = first(valid_dl)\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4460)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mnist_loss(preds, targets):\n",
    "    preds = preds.sigmoid()\n",
    "    return torch.where(targets==1, 1-preds, preds).mean()\n",
    "\n",
    "mnist_loss(torch.tensor([0.9, 0.4, 0.2]), tensor([1,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6667)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mnist_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()\n",
    "\n",
    "mnist_accuracy(torch.tensor([0.9, 0.4, 0.2]), tensor([1,0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all togather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.train.one_batch()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train_Loss Valid_Accuracy  Time\n",
      "Train loops: 12396\n",
      " 00:    0.0027     0.5152   3.5418\n",
      "Train loops: 12396\n",
      " 01:    0.0008     0.8371   3.7759\n",
      "Train loops: 12396\n",
      " 02:    0.0004     0.9176   3.3921\n",
      "Train loops: 12396\n",
      " 03:    0.0003     0.9421   3.3636\n",
      "Train loops: 12396\n",
      " 04:    0.0002     0.9578   3.3978\n",
      "Train loops: 12396\n",
      " 05:    0.0002     0.9661   3.4027\n",
      "Train loops: 12396\n",
      " 06:    0.0002     0.9676   3.3492\n",
      "Train loops: 12396\n",
      " 07:    0.0002     0.9686   3.3554\n",
      "Train loops: 12396\n",
      " 08:    0.0001     0.9696   3.4631\n",
      "Train loops: 12396\n",
      " 09:    0.0001     0.9720   3.3660\n",
      "Train loops: 12396\n",
      " 10:    0.0001     0.9740   3.4234\n",
      "Train loops: 12396\n",
      " 11:    0.0001     0.9740   3.4455\n",
      "Train loops: 12396\n",
      " 12:    0.0001     0.9755   3.4930\n",
      "Train loops: 12396\n",
      " 13:    0.0001     0.9755   3.4971\n",
      "Train loops: 12396\n",
      " 14:    0.0001     0.9760   3.4730\n",
      "Train loops: 12396\n",
      " 15:    0.0001     0.9760   3.7055\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[217], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m linear_model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m learner \u001b[38;5;241m=\u001b[39m MyLearner(dls, linear_model, mnist_loss, mnist_accuracy)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mlearner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[164], line 46\u001b[0m, in \u001b[0;36mMyLearner.fit\u001b[0;34m(self, epochs, lr)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     45\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 46\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     48\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_epoch()\n",
      "Cell \u001b[0;32mIn[164], line 23\u001b[0m, in \u001b[0;36mMyLearner.train_epoch\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m, opt):\n\u001b[1;32m     22\u001b[0m     updates \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m xb, yb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain:\n\u001b[1;32m     24\u001b[0m         updates \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     25\u001b[0m         pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(xb)\n",
      "File \u001b[0;32m~/code/course22/envs/lib/python3.9/site-packages/fastai/data/load.py:127\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_iter()\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__idxs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_idxs() \u001b[38;5;66;03m# called in context of main process (not workers/subprocesses)\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m _loaders[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfake_l\u001b[38;5;241m.\u001b[39mnum_workers\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfake_l):\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# pin_memory causes tuples to be converted to lists, so convert them back to tuples\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpin_memory \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(b) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m: b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(b)\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: b \u001b[38;5;241m=\u001b[39m to_device(b, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/code/course22/envs/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/code/course22/envs/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/code/course22/envs/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:41\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[0;32m~/code/course22/envs/lib/python3.9/site-packages/fastai/data/load.py:138\u001b[0m, in \u001b[0;36mDataLoader.create_batches\u001b[0;34m(self, samps)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m    137\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m o:o \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_item, samps))\n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunkify(res))\n",
      "File \u001b[0;32m~/code/course22/envs/lib/python3.9/site-packages/fastai/data/load.py:183\u001b[0m, in \u001b[0;36mDataLoader.do_batch\u001b[0;34m(self, b)\u001b[0m\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, b): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbefore_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/course22/envs/lib/python3.9/site-packages/fastai/data/load.py:173\u001b[0m, in \u001b[0;36mDataLoader.retain\u001b[0;34m(self, res, b)\u001b[0m\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretain\u001b[39m(\u001b[38;5;28mself\u001b[39m, res, b):  \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretain_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_listy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/course22/envs/lib/python3.9/site-packages/fastcore/dispatch.py:206\u001b[0m, in \u001b[0;36mretain_types\u001b[0;34m(new, old, typs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: t,typs \u001b[38;5;241m=\u001b[39m typs,\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(old) \u001b[38;5;28;01mif\u001b[39;00m old \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(old,\u001b[38;5;28mtype\u001b[39m(new)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(new)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m t(\u001b[43mL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyps\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_zip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/code/course22/envs/lib/python3.9/site-packages/fastcore/foundation.py:183\u001b[0m, in \u001b[0;36mL.map_zip\u001b[0;34m(self, f, cycled, *args, **kwargs)\u001b[0m\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_zip\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, \u001b[38;5;241m*\u001b[39margs, cycled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcycled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcycled\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstarmap(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/code/course22/envs/lib/python3.9/site-packages/fastcore/foundation.py:181\u001b[0m, in \u001b[0;36mL.zip\u001b[0;34m(self, cycled)\u001b[0m\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m, cycled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_cycle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcycled\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/course22/envs/lib/python3.9/site-packages/fastcore/foundation.py:111\u001b[0m, in \u001b[0;36mL._new\u001b[0;34m(self, items, *args, **kwargs)\u001b[0m\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_new\u001b[39m(\u001b[38;5;28mself\u001b[39m, items, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/course22/envs/lib/python3.9/site-packages/fastcore/foundation.py:98\u001b[0m, in \u001b[0;36m_L_Meta.__call__\u001b[0;34m(cls, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x,\u001b[38;5;28mcls\u001b[39m): \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/course22/envs/lib/python3.9/site-packages/fastcore/foundation.py:106\u001b[0m, in \u001b[0;36mL.__init__\u001b[0;34m(self, items, use_list, match, *rest)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, items\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39mrest, use_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, match\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (use_list \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_array(items):\n\u001b[0;32m--> 106\u001b[0m         items \u001b[38;5;241m=\u001b[39m \u001b[43mlistify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(items)\n",
      "File \u001b[0;32m~/code/course22/envs/lib/python3.9/site-packages/fastcore/basics.py:66\u001b[0m, in \u001b[0;36mlistify\u001b[0;34m(o, use_list, match, *rest)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mlist\u001b[39m): res \u001b[38;5;241m=\u001b[39m o\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_array(o): res \u001b[38;5;241m=\u001b[39m [o]\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mis_iter\u001b[49m(o): res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(o)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: res \u001b[38;5;241m=\u001b[39m [o]\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(28*28, 1)\n",
    "\n",
    "learner = MyLearner(dls, linear_model, mnist_loss, mnist_accuracy)\n",
    "\n",
    "learner.fit(20, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train_Loss Valid_Accuracy  Time\n",
      " 00:    0.4790     0.5414   0.2384\n",
      " 01:    0.4755     0.5839   0.1337\n",
      " 02:    0.4719     0.6342   0.0825\n",
      " 03:    0.4680     0.6914   0.0828\n",
      " 04:    0.4638     0.7490   0.0874\n",
      " 05:    0.4594     0.7969   0.1009\n",
      " 06:    0.4548     0.8354   0.0771\n",
      " 07:    0.4501     0.8598   0.0957\n",
      " 08:    0.4452     0.8760   0.0939\n",
      " 09:    0.4403     0.8906   0.0925\n",
      " 10:    0.4351     0.9013   0.0875\n",
      " 11:    0.4299     0.9145   0.0893\n",
      " 12:    0.4246     0.9262   0.0778\n",
      " 13:    0.4191     0.9331   0.0784\n",
      " 14:    0.4136     0.9389   0.0746\n",
      " 15:    0.4080     0.9453   0.0714\n",
      " 16:    0.4022     0.9492   0.0818\n",
      " 17:    0.3963     0.9516   0.0940\n",
      " 18:    0.3902     0.9526   0.0819\n",
      " 19:    0.3840     0.9521   0.0990\n"
     ]
    }
   ],
   "source": [
    "nn_basic = nn.Sequential(\n",
    "    nn.Linear(28*28, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 1),\n",
    ")\n",
    "\n",
    "learner = MyLearner(dls, nn_basic, mnist_loss, mnist_accuracy)\n",
    "\n",
    "learner.fit(20, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/james/.fastai/data/mnist_png/testing'),Path('/home/james/.fastai/data/mnist_png/training')]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 12000)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = (path/'training').ls().sorted()\n",
    "\n",
    "all_data = [(tensor(Image.open(o)), int(path.name))\n",
    "            for path in train_path\n",
    "            for o in (path).ls()]\n",
    "\n",
    "# shuffle\n",
    "\n",
    "random.shuffle(all_data)\n",
    "\n",
    "\n",
    "split = int(len(all_data)*0.8)\n",
    "\n",
    "train_data = all_data[:split]\n",
    "valid_data = all_data[split:]\n",
    "\n",
    "len(train_data), len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48000, 784]) torch.Size([48000, 1])\n",
      "48000\n",
      "torch.Size([12000, 784]) torch.Size([12000, 1])\n",
      "12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 784]), torch.Size([64, 1]))"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dl(data_list):\n",
    "    x = torch.stack([o[0] for o in data_list]).float()/255\n",
    "    x = x.view(-1, 28*28)\n",
    "    y = tensor([o[1] for o in data_list]).unsqueeze(1)\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "    dset = list(zip(x,y))\n",
    "\n",
    "    print(len(dset))\n",
    "\n",
    "    dl = DataLoader(dset, batch_size=64)\n",
    "\n",
    "    return dl\n",
    "\n",
    "train_dl = get_dl(train_data)\n",
    "valid_dl = get_dl(valid_data)\n",
    "\n",
    "train_dl.one_batch()[0].shape, valid_dl.one_batch()[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Needed function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_model = nn.Sequential(\n",
    "    nn.Linear(28*28, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 10)\n",
    ")\n",
    "\n",
    "mnist_model(train_dl.one_batch()[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 10]), torch.Size([64, 1]))"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = mnist_model(train_dl.one_batch()[0])\n",
    "targets = train_dl.one_batch()[1]\n",
    "\n",
    "preds.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 6, 8, 5, 6, 1, 8, 0, 1, 0, 8, 4, 2, 2, 8, 6, 3, 4, 4, 3, 2, 6, 7, 7,\n",
       "        1, 3, 4, 8, 5, 3, 9, 4, 4, 1, 8, 3, 4, 4, 1, 2, 4, 1, 0, 6, 6, 7, 2, 9,\n",
       "        7, 1, 7, 1, 4, 1, 8, 1, 7, 9, 2, 6, 6, 2, 7, 7])"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9775, 0.7523, 0.7815, 0.5587, 0.9547, 0.3564, 0.9957, 0.5457, 0.9605,\n",
       "         0.7544],\n",
       "        [0.7494, 0.8851, 0.9722, 0.9944, 0.3382, 0.7579, 0.5753, 0.2673, 0.1166,\n",
       "         0.3712],\n",
       "        [0.0948, 0.6444, 0.0074, 0.1551, 0.0752, 0.8233, 0.2820, 0.0842, 0.5581,\n",
       "         0.2289],\n",
       "        [0.2603, 0.6603, 0.6184, 0.3055, 0.7156, 0.6018, 0.3889, 0.0617, 0.7188,\n",
       "         0.6093],\n",
       "        [0.6258, 0.9553, 0.1366, 0.4280, 0.8662, 0.4507, 0.7663, 0.3752, 0.7364,\n",
       "         0.8468]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([9, 5, 7, 4, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.2939)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def complete_mnist_loss(preds, targets):\n",
    "    preds = preds.softmax(1)\n",
    "    # display(preds)\n",
    "    targets = targets.view(-1)\n",
    "    # targets_probs = preds[range(targets.shape[0]), targets]\n",
    "\n",
    "    # display(targets_probs)\n",
    "    # return -torch.log(targets_probs).mean()\n",
    "\n",
    "    # print(preds.shape, targets.shape)\n",
    "    # print(targets * preds.log())\n",
    "    # return -(targets * preds.log()).sum() / len(preds)\n",
    "    return nn.functional.cross_entropy(preds, targets.squeeze())\n",
    "    \n",
    "random_preds = tensor([[0.9775, 0.7523, 0.7815, 0.5587, 0.9547, 0.3564, 0.9957, 0.5457, 0.9605,\n",
    "         0.7544],\n",
    "        [0.7494, 0.8851, 0.9722, 0.9944, 0.3382, 0.7579, 0.5753, 0.2673, 0.1166,\n",
    "         0.3712],\n",
    "        [0.0948, 0.6444, 0.0074, 0.1551, 0.0752, 0.8233, 0.2820, 0.0842, 0.5581,\n",
    "         0.2289],\n",
    "        [0.2603, 0.6603, 0.6184, 0.3055, 0.7156, 0.6018, 0.3889, 0.0617, 0.7188,\n",
    "         0.6093],\n",
    "        [0.6258, 0.9553, 0.1366, 0.4280, 0.8662, 0.4507, 0.7663, 0.3752, 0.7364,\n",
    "         0.8468]])\n",
    "display(random_preds)\n",
    "random_targets = tensor([9, 5, 7, 4, 1])\n",
    "display(random_targets)\n",
    "complete_mnist_loss(random_preds, random_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7238, 0.4907, 0.3476, 0.7817, 0.4462, 0.8248, 0.2465, 0.5707, 0.4818,\n",
       "         0.0805],\n",
       "        [0.5778, 0.6755, 0.9743, 0.2956, 0.1529, 0.9657, 0.5931, 0.7790, 0.3862,\n",
       "         0.6850],\n",
       "        [0.5436, 0.1356, 0.9448, 0.0588, 0.6334, 0.4536, 0.7372, 0.5188, 0.8084,\n",
       "         0.1523],\n",
       "        [0.0838, 0.2554, 0.2245, 0.7093, 0.4754, 0.6429, 0.8939, 0.0266, 0.2164,\n",
       "         0.6699],\n",
       "        [0.2741, 0.1632, 0.1362, 0.8435, 0.7617, 0.7495, 0.5814, 0.1199, 0.7856,\n",
       "         0.2924]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 6, 7, 8])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.2000)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def complete_mnist_accuracy(preds, targets):\n",
    "    preds = preds.argmax(dim=1)\n",
    "    # display(preds)\n",
    "    correct = (preds == targets).float()\n",
    "    # display(correct)\n",
    "    return correct.float().mean()\n",
    "\n",
    "random_preds = torch.rand((5, 10))\n",
    "display(random_preds)\n",
    "random_targets = torch.randint(0, 10, (5,))\n",
    "display(random_targets)\n",
    "complete_mnist_accuracy(random_preds, random_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train_Loss Valid_Accuracy  Time\n",
      "Train loops: 750\n",
      " 00:    2.2277     0.1031   1.0366\n",
      "Train loops: 750\n",
      " 01:    2.2201     0.1037   0.7042\n",
      "Train loops: 750\n",
      " 02:    2.2125     0.1043   0.6485\n",
      "Train loops: 750\n",
      " 03:    2.2045     0.1050   0.6578\n",
      "Train loops: 750\n",
      " 04:    2.1960     0.1056   0.8106\n",
      "Train loops: 750\n",
      " 05:    2.1870     0.1059   0.7406\n",
      "Train loops: 750\n",
      " 06:    2.1773     0.1064   0.7597\n",
      "Train loops: 750\n",
      " 07:    2.1669     0.1066   0.7072\n",
      "Train loops: 750\n",
      " 08:    2.1557     0.1066   0.6518\n",
      "Train loops: 750\n",
      " 09:    2.1436     0.1069   0.6202\n",
      "Train loops: 750\n",
      " 10:    2.1307     0.1072   0.6093\n",
      "Train loops: 750\n",
      " 11:    2.1169     0.1076   0.6077\n",
      "Train loops: 750\n",
      " 12:    2.1025     0.1080   0.6503\n",
      "Train loops: 750\n",
      " 13:    2.0877     0.1086   0.7099\n",
      "Train loops: 750\n",
      " 14:    2.0725     0.1092   0.7276\n",
      "Train loops: 750\n",
      " 15:    2.0571     0.1097   0.6900\n",
      "Train loops: 750\n",
      " 16:    2.0414     0.1100   0.6446\n",
      "Train loops: 750\n",
      " 17:    2.0257     0.1104   0.6531\n",
      "Train loops: 750\n",
      " 18:    2.0098     0.1106   0.6639\n",
      "Train loops: 750\n",
      " 19:    1.9938     0.1107   0.7486\n"
     ]
    }
   ],
   "source": [
    "\n",
    "learner = MyLearner(dls, mnist_model, complete_mnist_loss, complete_mnist_accuracy)\n",
    "\n",
    "learner.fit(20, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mnist_accuracy() got an unexpected keyword argument 'lr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[343], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m fastai_learner \u001b[38;5;241m=\u001b[39m Learner(dls, mnist_model, mnist_loss, mnist_accuracy)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mfastai_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/course22/envs/lib/python3.9/site-packages/fastai/learner.py:259\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    257\u001b[0m     cbs \u001b[38;5;241m=\u001b[39m L(cbs) \u001b[38;5;241m+\u001b[39m SkipToEpoch(start_epoch)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madded_cbs(cbs):\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reset_opt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: wd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwd\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mset_hypers(wd\u001b[38;5;241m=\u001b[39mwd)\n",
      "File \u001b[0;32m~/code/course22/envs/lib/python3.9/site-packages/fastai/learner.py:188\u001b[0m, in \u001b[0;36mLearner.create_opt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mclear_state()\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwd_bn_bias:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bn_bias_state(\u001b[38;5;28;01mTrue\u001b[39;00m ): p[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdo_wd\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: mnist_accuracy() got an unexpected keyword argument 'lr'"
     ]
    }
   ],
   "source": [
    "fastai_learner = Learner(dls, mnist_model, mnist_loss, mnist_accuracy)\n",
    "\n",
    "fastai_learner.fit(20, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 8, 8, 1, 4, 8, 1, 8, 4, 0, 4, 4, 4, 8, 4, 8, 1, 4, 4, 9, 9, 4, 4, 8,\n",
       "        9, 8, 4, 8, 4, 9, 8, 4, 4, 8, 8, 1, 8, 8, 4, 9, 4, 4, 8, 8, 4, 8, 8, 8,\n",
       "        8, 4, 8, 4, 8, 4, 4, 9, 1, 8, 8, 4, 4, 1, 4, 8])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_model(train_dl.one_batch()[0]).argmax(dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
